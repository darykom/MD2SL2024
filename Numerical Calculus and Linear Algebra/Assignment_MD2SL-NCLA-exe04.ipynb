{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1xGvbSSx_3ltcZNooL4tS0oGQBgg-oJPU","timestamp":1717181580391}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# MD2DS - Master in Data Science and Statistical Learning\n","\n","**Numerical Calculus and Linear Algebra**\n","\n","Exercise: SOR\n","\n","Deadline: 1/5/2024"],"metadata":{"id":"ef4QTtBT8e0j"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"C9oHqeCj8OSr","executionInfo":{"status":"ok","timestamp":1717267478023,"user_tz":-120,"elapsed":321,"user":{"displayName":"Dario Comanducci","userId":"13956551013362018059"}}},"outputs":[],"source":["import numpy as np\n","from scipy.sparse import csr_matrix, diags, tril\n","from scipy.sparse.linalg import spsolve_triangular"]},{"cell_type":"markdown","source":["# Exercise\n","\n","Consider a linear system $A\\mathbf{x} = \\mathbf{b}$.\n","1.  Write a python function `my_SOR(A, x0, b, omega, tol, kmax)` that takes in input\n","\n","  -  $A\\in\\mathbb{R}^{m\\times m}$  : square matrix\n","  -  $\\mathbf{x}_0\\in\\mathbb{R}^m$   : a first approximation of the system solution\n","  -  $\\mathbf{b}\\in\\mathbb{R}^m$   : costant vector\n","  -  $\\omega\\in(0,2)$                      : the relxation parameter\n","  -  $\\texttt{tol}\\in\\mathbb{R}$   : a given tolerance\n","  -  $\\texttt{kmax}\\in\\mathbb{N}$  : a maximum number of iterations\n","\n","  and returns\n","  -  $\\mathbf{x}\\in\\mathbb{R}^m$ : the approximation of the solution of the linear system, obtained by implementing the Successive Over Relaxation method;\n","  -  $\\texttt{it}$ : the number of the computed iterations.\n","\n","2.  Let\n","\\begin{equation}\n","      T_n = \\pmatrix{ 3       & -1     &        & \\huge 0 \\\\\n","                     -1       & 3      & \\ddots & \\\\\n","                              & \\ddots & \\ddots & -1 \\\\\n","                     \\huge 0 &      & -1      & 3  }\\in\\mathbb{R}^{n \\times n}\n","\\end{equation}\n","\n","  and define the sparse (possibly use the sparse format: $\\texttt{csr_matrix}$) matrix $A\\in\\mathbb{R}^{n^2\\times n^2}$ as\n","      \\begin{equation}\n","        A = T_n \\otimes I_n + I_n \\otimes T_n.\n","      \\end{equation}\n","\n","  For $n=10,20,\\dots,50$ solve the linear system $A\\mathbf{x} = \\mathbf{b}$ with exact solution $\\mathbf{x} = \\pmatrix{1\\\\2\\\\\\vdots\\\\n^2}\\in\\mathbb{R}^{n^2}$ using the funcion `my_SOR` implemented at point (1) with\n","  - $\\mathbf{x}_0 = \\pmatrix{0\\\\\\vdots\\\\0}\\in\\mathbb{R}^{n^2}$\n","  - $\\omega = 0.8, 1, 1.2$\n","  - $\\texttt{toll} = 10^{-5}$\n","  - $\\texttt{kmax} = 10^{5}$\n","  \n","  Print\n","  -  the condition number of $A$,\n","  -  the number of computed iterations $\\texttt{it}$,\n","  -  the relative error."],"metadata":{"id":"g29tKQr782Yl"}},{"cell_type":"markdown","source":["Solution 1.1\n","\n","Considerando che anche nel SOR vale\n","\\begin{equation}\n","A = M_\\omega - N_\\omega\n","\\end{equation}\n","possiamo sviluppare la relazione (seguendo gli stessi passaggi fatti per Gauss-Seidel e Jacobi)\n","\\begin{equation}\n","\\mathbf{x}^{(k+1)} = M_\\omega^{-1} N_\\omega \\mathbf{x}^{(k)} + M_\\omega^{-1} \\mathbf{b}\n","\\end{equation}\n","giungendo a\n","\\begin{equation}\n","\\begin{cases}\n","\\mathbf{r}^{(k)} &= \\mathbf{b}-A \\mathbf{x}^{(k)}\\\\\n","M_\\omega \\mathbf{y}^{(k)}(\\omega) &= \\mathbf{r}^{(k)} \\\\\n","\\mathbf{x}^{(k+1)} &= \\mathbf{x}^{(k)} + \\mathbf{y}^{(k)}\n","\\end{cases}\n","\\end{equation}\n","\n","Possiamo ulteriolmente scomporre il precedente sistema in base alla definizione di $M_\\omega = \\omega^{-1} (D - \\omega L)$:\n","\\begin{equation}\n","\\omega^{-1}(D - \\omega L)\\, \\mathbf{y}^{(k)} = \\mathbf{r}^{(k)} \\qquad \\Rightarrow \\qquad (D-\\omega L)\\, \\mathbf{y}^{(k)}(\\omega) = \\omega\\, \\mathbf{r}^{(k)}\n","\\end{equation}\n","\n","Nella versione di Gauss-Seidel viene calcolato $M\\,\\mathbf{y}^{(k)} = \\mathbf{r}^{(k)}$ sfruttando il meccanismo di risoluzione delle matrici triangolari inferiori  ($M= D-L = \\mathtt{tril}(A)$); qui possiamo adattare il procedimento a $D-\\omega L$ dove la componente triangolare stretta di A (cioè $-L$) è moltiplicata per $\\omega$:\n","\\begin{equation}\n","A = \\begin{bmatrix}\n","a_{11} & a_{12} & \\dots  & a_{1n} \\\\\n","a_{21} & a_{22} & \\dots  & a_{2n} \\\\\n","\\vdots & \\vdots & \\ddots & \\vdots \\\\\n","a_{n1} & a_{n2} & \\dots  & a_{nn} \\\\\n","\\end{bmatrix} \\qquad \\Rightarrow \\qquad\n","D = \\begin{bmatrix}\n","a_{11} &        &        &      \\\\\n","       & a_{22} &        &      \\\\\n","       &        & \\ddots &      \\\\\n","       &        &        &a_{nn}\\\\\n","\\end{bmatrix}\n","\\quad\n","L = \\begin{bmatrix}\n","          0 &          &        &            &   \\\\\n","   -a_{2,1} &   \\ddots &        &            &   \\\\\n","     \\vdots &   \\ddots & \\ddots &            &   \\\\\n"," -a_{n-1,1} &   \\ddots & \\ddots &     \\ddots &   \\\\\n","   -a_{n,1} & -a_{n,2} &  \\dots & -a_{n,n-1} & 0 \\\\\n","\\end{bmatrix}\n","\\end{equation}\n","\n","\\begin{equation}\n","D-\\omega L = \\begin{bmatrix}\n","              a_{1,1} &                  &        &                  &         \\\\\n","   \\omega\\,   a_{2,1} &           \\ddots &        &                  &         \\\\\n","               \\vdots &           \\ddots & \\ddots &                  &         \\\\\n","   \\omega\\, a_{n-1,1} &           \\ddots & \\ddots &           \\ddots &         \\\\\n","   \\omega\\,   a_{n,1} & \\omega\\, a_{n,2} &  \\dots & \\omega\\,a_{n,n-1} & a_{n,n} \\\\\n","\\end{bmatrix}\n","\\end{equation}\n","\n","Per cui da $\\mathtt{tril}(A)\\, \\mathbf{y} = \\mathbf{r}$, ossia\n","\\begin{equation}\n","\\begin{cases}\n","y_1 = r_1/a_{11}\\\\\n","y_2 = (r_2-a_{21} y_1)/a_{22} \\\\\n","\\vdots\\\\\n","y_n = \\big(r_n- \\sum_{j=1}^{n-1}a_{nj} y_j \\big)/ a_{nn}\n","\\end{cases}\n","\\end{equation}\n","\n","otteniamo per $(D-\\omega L)\\, \\mathbf{y}(\\omega) =  \\omega\\, \\mathbf{r}$:\n","\n","\\begin{equation}\n","\\begin{cases}\n","y_1(\\omega) = \\omega\\, r_1/a_{11}\\\\\n","y_2(\\omega) = (\\omega\\, r_2-\\omega\\, a_{21} y_1(\\omega))/a_{22} = \\omega\\, (r_{2}-a_{21})/a_{22} \\\\\n","y_3(\\omega) = (\\omega r_3 -\\omega a_{32} y_2(\\omega) - \\omega a_{31} y_1(\\omega))/a_{33} = \\omega (r_3 - a_{32} y_2(\\omega) - a_{31} y_1(\\omega) ) /a_{33} \\\\\n","\\vdots\\\\\n","y_n(\\omega) = \\big(\\omega\\,r_n- \\omega \\sum_{j=1}^{n-1}a_{nj} y_j(\\omega) \\big)/ a_{nn} = \\omega\\, \\big(r_n- \\sum_{j=1}^{n-1}a_{nj} y_j (\\omega) \\big)/ a_{nn}\n","\\end{cases}\n","\\end{equation}\n","\n","Pertanto al passo $k$ avremo che $\\mathbf{x}^{(k+1)}$ si ottiene da\n","\\begin{equation}\n","\\begin{cases}\n","\\mathbf{r}^{(k)} &= \\mathbf{b}-A \\mathbf{x}^{(k)}\\\\\n","(D-\\omega L)\\, \\mathbf{y}^{(k)} &= \\omega \\mathbf{r}^{(k)} \\\\\n","\\mathbf{x}^{(k+1)} &= \\mathbf{x}^{(k)} + \\mathbf{y}^{(k)}\n","\\end{cases}\n","\\end{equation}\n","\n","\n","La funzione $\\texttt{lowerTriangularRelaxed}$ risolve il sistema $(D-\\omega L) \\mathbf{y} = \\omega\\, \\mathbf{r}$, per essere poi integrata nel flusso di elaborazione analogo a quello di Jacobi o Gauss-Seidel.\n"],"metadata":{"id":"TdcjQIBW_-Y1"}},{"cell_type":"code","source":["import numpy as np\n","from scipy.sparse import csr_matrix, diags, tril\n","from scipy.sparse.linalg import spsolve_triangular\n","\n","\n","def lowerTriangularRelaxed(A,r,w):\n","  # A: lower triangular coefficient matrix\n","  # b: vector of costant terms\n","  # w: relax factor\n","  y = r.copy() # it is necessary to copy b, otherwise it will also be changed as y is.\n","  y[0] = w*y[0]/A[0,0];\n","  for i in range(1,A.shape[0]): # row access\n","    y[i] = w*(y[i] - A[i,0:i]@y[0:i])\n","    y[i] = y[i] / A[i,i]\n","  return y\n","\n","def my_sor(A, x, b, w, toll, kmax):\n","    n = len(b)\n","    nrb = np.linalg.norm(b)\n","    go = True\n","    it = 1\n","    while it<=kmax and go:\n","        r = b - A @ x\n","        go = (np.linalg.norm(r) > toll*nrb)\n","        if go:\n","            it += 1\n","            x = x + lowerTriangularRelaxed(A,r,w)\n","    it -= 1\n","    return x, it\n","\n"],"metadata":{"id":"7cMgVFlrXzN8","executionInfo":{"status":"ok","timestamp":1717267482890,"user_tz":-120,"elapsed":296,"user":{"displayName":"Dario Comanducci","userId":"13956551013362018059"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Solution 2\n","\n"],"metadata":{"id":"jjWnYFIF26vY"}},{"cell_type":"code","source":["toll = 1e-5\n","kmax = 1e5\n","\n","print('n  cond   w    it  rel_err')\n","for n in range(10, 60, 10):\n","\n","    T = np.diag(3*np.ones(n)) - np.diag(np.ones(n-1),1) - np.diag(np.ones(n-1),-1)\n","    A = np.kron(T,np.eye(n))+np.kron(np.eye(n),T)\n","\n","    N = n**2\n","    xex = np.ones(N) # exact solution\n","    for k in range(1,(N+1),1):\n","        xex[k-1] = k\n","    b = A @ xex\n","\n","    x0 = np.zeros(N)\n","    print('---------------------------')\n","    for w in (0.8, 1, 1.2):\n","\n","        x, it = my_sor(A, x0, b, w, toll, kmax)\n","        xerr = np.linalg.norm(x-xex)/np.linalg.norm(xex)\n","        print(f'{n} {np.linalg.cond(A):.2f}   {w:.1f}  {it}  {xerr:.2e}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"flXRJZrswJQJ","executionInfo":{"status":"ok","timestamp":1717267532834,"user_tz":-120,"elapsed":43444,"user":{"displayName":"Dario Comanducci","userId":"13956551013362018059"}},"outputId":"e1ae4956-a0ec-467b-fb5a-f8e3f1000f2f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["n  cond   w    it  rel_err\n","---------------------------\n","10 4.55   0.8  23  1.09e-05\n","10 4.55   1.0  15  1.01e-05\n","10 4.55   1.2  12  1.57e-06\n","---------------------------\n","20 4.87   0.8  25  8.08e-06\n","20 4.87   1.0  16  1.01e-05\n","20 4.87   1.2  11  4.13e-06\n","---------------------------\n","30 4.94   0.8  25  9.48e-06\n","30 4.94   1.0  17  5.85e-06\n","30 4.94   1.2  11  4.55e-06\n","---------------------------\n","40 4.96   0.8  25  1.02e-05\n","40 4.96   1.0  17  6.29e-06\n","40 4.96   1.2  11  4.80e-06\n","---------------------------\n","50 4.98   0.8  26  6.74e-06\n","50 4.98   1.0  17  6.56e-06\n","50 4.98   1.2  11  4.95e-06\n"]}]},{"cell_type":"markdown","source":["Data la natura tridiagonale di $T_n$, i prodotti $T_n \\otimes I_n$ e $T_n \\otimes I_n$ producono rispettivamente la matrici\n","\\begin{align*}\n","T_n \\otimes I_n &=\n","\\begin{bmatrix}\n","3 I_n &   -I_n &        &     \\\\\n"," -I_n &   3I_n & \\ddots &     \\\\\n","      & \\ddots & \\ddots & -I_n\\\\\n","      &        &   -I_n & 3I_n\\\\\n","\\end{bmatrix}\\\\\n","%\n","I_n \\otimes T_n &=\n","\\begin{bmatrix}\n","  T_n &        &        &     \\\\\n","      &    T_n &        &     \\\\\n","      &        & \\ddots &     \\\\\n","      &        &        & 3I_n\\\\\n","\\end{bmatrix}\\\\\n","\\end{align*}\n","da cui\n","\\begin{equation}\n","T_n \\otimes I_n + T_n \\otimes I_n =\n","\\begin{bmatrix}\n","3I_n+T_n &     -I_n &        &         \\\\\n","    -I_n & 3I_n+T_n & \\ddots &         \\\\\n","         &   \\ddots & \\ddots & -I_n    \\\\\n","         &          &   -I_n & 3I_n+T_n\\\\\n","\\end{bmatrix}\n","\\end{equation}\n","\n","Per creare la matrice in formato sparso, è stata sfruttata la sua forma a diagonali:\n","* la diagonale principale ($k=0$) ha tutti elementi 6\n","* le diagonali per $k=\\pm n$ hanno tutti valori -1\n","* le diagonali per $k=\\pm 1$ sono composte tutte da -1, eccetto ogni $n$ elementi dove valgono 0"],"metadata":{"id":"Nt8OlodL_WKh"}},{"cell_type":"code","source":["def CreateMatrixSparseA(n):\n","    N = n*n\n","    diag0 = np.full(N,6)\n","    diagn = np.full(N-n,-1)\n","\n","    diag1 = np.full(N-1,-1)\n","    mask = ((1+np.arange(len(diag1))) % n) == 0\n","    diag1[mask]=0\n","\n","    Asc = diags([diag0, diag1, diag1, diagn, diagn], [0, -1, 1, -n, n])\n","    return Asc.tocsr()\n","\n","def lowerTriangularRelaxedSparse(Asp,r,w):\n","    d = Asp.diagonal()\n","    L = tril(Asp, k=-1, format='csr')\n","    Mw = diags(d,0) + w*L;\n","    y = spsolve_triangular(Mw, w*r)\n","    return y\n","\n","def sparse_sor(Asp, x, b, w, toll, kmax):\n","    n = len(b)\n","    nrb = np.linalg.norm(b)\n","    go = True\n","    it = 1\n","    while it<=kmax and go:\n","        r = b - Asp.dot(x)\n","        go = (np.linalg.norm(r) > toll*nrb)\n","        if go:\n","            it += 1\n","            x = x + lowerTriangularRelaxedSparse(Asp,r,w)\n","    it -= 1\n","    return x, it\n","\n","\n","\n","#---------------------------------------------------------------\n","# check sulla correttezza di CreateMatrixSparseA(n)\n","n = 10\n","T = np.diag(3*np.ones(n)) - np.diag(np.ones(n-1),1) - np.diag(np.ones(n-1),-1)\n","Afull = np.kron(T,np.eye(n))+np.kron(np.eye(n),T)\n","Asparse = CreateMatrixSparseA(n);\n","print('n=' + str(n) +  ': check |Afull-Asparse| = ' + str(np.linalg.norm(Afull-Asparse.toarray())))\n","\n","\n","\n","print('\\nn  w   it rel_err')\n","for n in range(10, 60, 10):\n","\n","    Asp = CreateMatrixSparseA(n)\n","\n","    N = n**2\n","    xex = np.ones(N) # exact solution\n","    for k in range(1,(N+1),1):\n","        xex[k-1] = k\n","    b = Asp.dot(xex)\n","\n","    x0 = np.zeros(N)\n","    print('-------------------------------------')\n","    for w in (0.8, 1, 1.2):\n","\n","        x, it = sparse_sor(Asp, x0, b, w, toll, kmax)\n","        xerr = np.linalg.norm(x-xex)/np.linalg.norm(xex)\n","        print(f'{n} {w:.1f} {it} {xerr:.2e}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s2Gn3pKpSJ5K","executionInfo":{"status":"ok","timestamp":1717267550764,"user_tz":-120,"elapsed":6088,"user":{"displayName":"Dario Comanducci","userId":"13956551013362018059"}},"outputId":"8d1ec54d-a4a7-430b-e4c2-8e8d2e2ea5c6"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["n=10: check |Afull-Asparse| = 0.0\n","\n","n  w   it rel_err\n","-------------------------------------\n","10 0.8 23 1.09e-05\n","10 1.0 15 1.01e-05\n","10 1.2 12 1.57e-06\n","-------------------------------------\n","20 0.8 25 8.08e-06\n","20 1.0 16 1.01e-05\n","20 1.2 11 4.13e-06\n","-------------------------------------\n","30 0.8 25 9.48e-06\n","30 1.0 17 5.85e-06\n","30 1.2 11 4.55e-06\n","-------------------------------------\n","40 0.8 25 1.02e-05\n","40 1.0 17 6.29e-06\n","40 1.2 11 4.80e-06\n","-------------------------------------\n","50 0.8 26 6.74e-06\n","50 1.0 17 6.56e-06\n","50 1.2 11 4.95e-06\n"]}]}]}